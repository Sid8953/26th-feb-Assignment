{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cddf8f53-935d-4306-8e8b-3406e93ab297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2022.6)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d34fbbbc-8cd6-4771-b818-0e5790dabcc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Consider following code to answer further questions:\n",
    "import pandas as pd\n",
    "course_name = ['Data Science', 'Machine Learning', 'Big Data', 'Data Engineer']\n",
    "duration = [2,3,6,4]\n",
    "df = pd.DataFrame(data = {'course_name' : course_name, 'duration' : duration})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1903c385-a3ac-4222-a560-c0a4b1b36a03",
   "metadata": {},
   "source": [
    "# Ans 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb934178-1ae3-41e3-bf89-0bc0dfc3e95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "course_name    Machine Learning\n",
       "duration                      3\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d1a4f6-5f3c-4c40-89a4-826c8021bebe",
   "metadata": {},
   "source": [
    "# Ans 2\n",
    "\n",
    "loc and iloc are both methods in the pandas library that allow you to select data from a DataFrame based on indices or labels.\n",
    "\n",
    "loc is primarily label-based, meaning that it is used to select data based on row labels and column names. You can use loc to select rows and columns by passing the row label(s) and column label(s) as arguments. For example, to select the value in row 'A' and column 'B' of a DataFrame df, you would use df.loc['A', 'B'].\n",
    "\n",
    "iloc, on the other hand, is primarily integer-based, meaning that it is used to select data based on the integer position of the rows and columns. You can use iloc to select rows and columns by passing the row index(es) and column index(es) as arguments. For example, to select the value in the first row and second column of a DataFrame df, you would use df.iloc[0, 1]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b4ef74-1b96-4453-af0d-9a3044c45e06",
   "metadata": {},
   "source": [
    "# Ans 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3f1bc4c-4e18-415b-96bc-5afc404e565d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1,2,3,4,5,6]\n",
    "#Creating a dataframe:\n",
    "df1 = pd.DataFrame(np.random.rand(6,6), columns = columns, index = indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d478d7d9-6a83-4fd2-8be2-52ff5abbf97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "column_1    0.696954\n",
       "column_2    0.598556\n",
       "column_3    0.871830\n",
       "column_4    0.875130\n",
       "column_5    0.462360\n",
       "column_6    0.133802\n",
       "Name: 2, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df = df1.reindex([3,0,1,2])\n",
    "new_df .loc[2]      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febb27ac-9a7a-4d23-a287-440ceb6c0224",
   "metadata": {},
   "source": [
    "# Ans 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55991775-15dd-448f-992c-e991e04f0b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "column_1    0.706736\n",
       "column_2    0.575666\n",
       "column_3    0.535644\n",
       "column_4    0.486494\n",
       "column_5    0.485750\n",
       "column_6    0.477869\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e4ff15f-c834-4922-8495-979a0ce04d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19370428949676674"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['column_2'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f92aceb-9fe8-40af-a615-c88f6a306b21",
   "metadata": {},
   "source": [
    "# Ans 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85c55e2d-25c3-4f5a-95f7-07628b81fe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
    "indices = [1,2,3,4,5,6]\n",
    "#Creating a dataframe:\n",
    "df1 = pd.DataFrame(np.random.rand(6,6), columns = columns, index = indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4384fe4-32de-45c3-ad1d-50401e906f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc['column_2',1]= \"name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34c6061a-078f-4c23-8255-0dfb30f7f708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4469658154383303"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['column_2'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a070487-96c9-48fd-86eb-cbf39b94b981",
   "metadata": {},
   "source": [
    "# Ans 6\n",
    "\n",
    "In pandas, a window function (also known as a rolling or sliding window) is a function that operates on a specified window of data in a time series or DataFrame. The window moves over the data in a specified direction, such as forward or backward, and calculates a statistic or value for each window.\n",
    "\n",
    "The different types of window functions available in pandas are:\n",
    "\n",
    "Rolling: This function creates a rolling window object that can be used to perform calculations on a rolling window of data. The window can be specified using the window size, which can be either a number of periods or a time frequency.\n",
    "\n",
    "Expanding: This function creates an expanding window object that can be used to perform calculations on an expanding window of data. The window starts from the first period and includes all preceding periods.\n",
    "\n",
    "Exponentially weighted: This function creates an exponentially weighted moving window object that can be used to perform calculations on a moving window of data. The window size can be specified using the span or the center of mass, which controls the rate at which the weights decrease over time.\n",
    "\n",
    "Rolling with time-based offsets: This function creates a rolling window object that uses a time-based offset to define the window size. The window can be specified using a time frequency, such as hours, days, or weeks.\n",
    "\n",
    "Rolling with variable-length windows: This function creates a rolling window object that has a variable-length window size. The window size can be defined based on the values in the data or using a function that calculates the window size.\n",
    "\n",
    "These window functions can be used to perform various calculations on time series data, such as calculating rolling means, cumulative sums, and exponential moving averages. They are powerful tools for analyzing and visualizing time series data in pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2628a444-018d-4d39-97f3-0e087d6a946a",
   "metadata": {},
   "source": [
    "# Ans 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1354a53e-1f49-420f-901a-4a599d1bf06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current month:  12\n",
      "Current year:  2023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_109/1498775486.py:4: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  current_date = pd.datetime.now()\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# get the current date and time\n",
    "current_date = pd.datetime.now()\n",
    "\n",
    "# extract the month and year from the current date\n",
    "current_month = current_date.month\n",
    "current_year = current_date.year\n",
    "\n",
    "# print the month and year\n",
    "print(\"Current month: \", current_month)\n",
    "print(\"Current year: \", current_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22149a91-e778-4f3b-97a4-df32159484ff",
   "metadata": {},
   "source": [
    "# Ans 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9dad2c5-310a-47cc-8265-3f5376287556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter first date (YYYY-MM-DD):  2023-02-27\n",
      "Enter second date (YYYY-MM-DD):  2023-04-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between 2023-02-27 and 2023-04-05 is:\n",
      "37 days, 888 hours, 0 minuts\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Prompt user to enter two dates in the format YYYY-MM-DD\n",
    "date1 = input(\"Enter first date (YYYY-MM-DD): \")\n",
    "date2 = input(\"Enter second date (YYYY-MM-DD): \")\n",
    "\n",
    "# Convert user input to datetime objects\n",
    "date1 = pd.to_datetime(date1)\n",
    "date2 = pd.to_datetime(date2)\n",
    "\n",
    "# Calculate difference between dates using Pandas time delta\n",
    "delta = date2 - date1\n",
    "\n",
    "# Calculate total number of minutes and hours in delta\n",
    "total_minutes = delta.total_seconds() / 60\n",
    "total_hours = total_minutes / 60\n",
    "\n",
    "# Display result\n",
    "print(\"Difference between\", date1.date(), \"and\", date2.date(), \"is:\")\n",
    "print(delta.days, \"days,\", int(total_hours), \"hours,\", int(total_minutes) % 60, \"minuts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28c88d8-943d-41ee-8d3e-137b6c072e0d",
   "metadata": {},
   "source": [
    "# Ans 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453ecf27-3beb-4114-a8b6-9099d5d873a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# prompt the user to enter the file path, column name, and category order\n",
    "file_path = input(\"Enter the file path: \")\n",
    "col_name = input(\"Enter the column name: \")\n",
    "categories = input(\"Enter the category order (comma-separated): \").split(\",\")\n",
    "\n",
    "# read the CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# convert the specified column to categorical data type\n",
    "df[col_name] = pd.Categorical(df[col_name], categories=categories, ordered=True)\n",
    "\n",
    "# display the sorted data\n",
    "print(df.sort_values(by=[col_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9347ea8-be66-46e2-a25d-43d796e438ec",
   "metadata": {},
   "source": [
    "# Ans 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b21965-1f57-4b6b-b100-6cb542958116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# prompt the user to enter the file path\n",
    "file_path = input(\"Enter the file path: \")\n",
    "\n",
    "# read the CSV file\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# create a pivot table to group the data by product category and year\n",
    "pivot = pd.pivot_table(df, values='month_number', index='total_units', columns='total_profit', aggfunc='sum')\n",
    "\n",
    "# plot the stacked bar chart\n",
    "pivot.plot(kind='bar', stacked=True)\n",
    "\n",
    "# set the chart title and axis labels\n",
    "plt.title('Sales by Product Category')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Sales')\n",
    "\n",
    "# display the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5453b82f-2e75-4e53-a329-878aa3721427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
